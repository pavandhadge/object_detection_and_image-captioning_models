{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv2lPfz8iH62",
        "outputId": "e946b075-81e6-4579-d349-708cda51aad8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install transformers opencv-python\n",
        "!pip install timm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  DINOv2 (DEtection Transformer V2) by Meta AI.\n",
        "\"\"\"\n",
        "# DINOv2 (DEtection Transformer V2) - Object Detection with Meta AI's DETR\n",
        "\n",
        "## Overview:\n",
        "This script performs **object detection** using **DINOv2 (DEtection Transformer V2)**, a powerful model by **Meta AI** based on **DETR (DEtection TRansformer)**. It leverages a **ResNet-101 backbone** for feature extraction and **transformers for end-to-end object detection**.\n",
        "\n",
        "## Steps:\n",
        "1. **Load Dependencies & DINOv2 Model**\n",
        "   - Uses **PyTorch** and **Hugging Face Transformers** to load `facebook/detr-resnet-101`.\n",
        "   - Runs on **GPU (CUDA) if available, otherwise uses CPU**.\n",
        "\n",
        "2. **Preprocess Input Image**\n",
        "   - Loads and converts the image to **RGB** using PIL.\n",
        "   - Uses **DETR's image processor** to prepare the image tensor for inference.\n",
        "\n",
        "3. **Object Detection**\n",
        "   - Passes the processed image through the **DINOv2 model** for inference.\n",
        "   - Extracts bounding boxes, object labels, and confidence scores.\n",
        "\n",
        "4. **Post-Processing & Visualization**\n",
        "   - Filters results based on a confidence `threshold`.\n",
        "   - Draws bounding boxes and object labels on the original image.\n",
        "   - Saves and displays the **annotated output image** using OpenCV & Matplotlib.\n",
        "\n",
        "## Notes:\n",
        "- **DETR (DEtection TRansformer)** eliminates the need for hand-crafted anchors and post-processing steps like **NMS (Non-Maximum Suppression)**.\n",
        "- **DINOv2 improves detection accuracy and generalization** compared to previous transformer-based models.\n",
        "- **Adjustable detection threshold** helps control false positives and precision.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "import matplotlib.pyplot as plt\n",
        "# Load DINOv2 Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-101\")\n",
        "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-101\").to(device)\n",
        "\n",
        "# Image Preprocessing\n",
        "def load_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    return image\n",
        "\n",
        "def detect_objects(image_path, threshold=0.2):\n",
        "    image = load_image(image_path)\n",
        "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract results\n",
        "    target_sizes = torch.tensor([image.size[::-1]]).to(device)\n",
        "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=threshold)[0]\n",
        "\n",
        "    # Draw boxes on image\n",
        "    image_cv = cv2.imread(image_path)\n",
        "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "        if score > threshold:\n",
        "            box = [int(i) for i in box]\n",
        "            cv2.rectangle(image_cv, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
        "            cv2.putText(image_cv, f\"{model.config.id2label[label.item()]}: {score:.2f}\",\n",
        "                        (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    cv2.imwrite(\"output.jpg\", image_cv)\n",
        "    return \"output.jpg\"\n",
        "\n",
        "# Example Usage\n",
        "image_path =  \"/content/20250326_232148.jpg\"\n",
        "output_image_ = detect_objects(image_path)\n",
        "output_image = cv2.imread(output_image_)\n",
        "output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(output_image)\n",
        "plt.axis(\"off\")  # Hide axes\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "j3BnkAb3iWl6",
        "outputId": "eb72d892-5680-4b82-9e41-fbd2b2144aae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')  # This is also required for wordnet to work properly\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBXQfXXHiXhE",
        "outputId": "b3abd216-da45-4169-87bd-83e8fcb4bcda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Object Detection & NLP-based Object Matching using DINO (DEtection Transformer) and NLP\n",
        "----------------------------------------------------------------------------------------\n",
        "## Overview:\n",
        "This script performs object detection in images using Meta AI's **DINO (DETR ResNet-101)** model and\n",
        "matches the detected objects with user-specified textual descriptions. It leverages **Natural Language Processing (NLP)**\n",
        "for extracting object names from text and **WordNet** for finding synonyms. Fuzzy string matching is also used to improve matching accuracy.\n",
        "\n",
        "## Key Technologies & Libraries Used:\n",
        "1. **PyTorch & Hugging Face Transformers**:\n",
        "   - Loads and runs the **DINOv2 (DETR ResNet-101)** object detection model.\n",
        "   - Uses `AutoProcessor` for preprocessing images before feeding them into the model.\n",
        "   - Uses `AutoModelForObjectDetection` for detecting objects in the image.\n",
        "\n",
        "2. **OpenCV (cv2)**:\n",
        "   - Reads and processes images.\n",
        "   - Draws bounding boxes and labels on detected objects.\n",
        "\n",
        "3. **spaCy (Natural Language Processing)**:\n",
        "   - Extracts nouns from a user-provided text description of objects to be found in the image.\n",
        "\n",
        "4. **WordNet (NLTK)**:\n",
        "   - Generates synonyms for detected and user-provided object names to improve matching accuracy.\n",
        "\n",
        "5. **RapidFuzz (Fuzzy Matching for Object Names)**:\n",
        "   - Matches detected object names with caption words based on similarity percentage.\n",
        "\n",
        "## Process Flow:\n",
        "1. **Load DINO Object Detection Model**:\n",
        "   - Load the **DINOv2 model (DETR ResNet-101)** for object detection.\n",
        "   - Load the **Hugging Face AutoProcessor** for image preprocessing.\n",
        "\n",
        "2. **Extract Object Names from Text Input (Caption Matching)**:\n",
        "   - Parse the text input using `spaCy` to extract **nouns** (e.g., \"chair\", \"bottle\").\n",
        "   - Retrieve synonyms for each word using `WordNet`.\n",
        "\n",
        "3. **Perform Object Detection on Image**:\n",
        "   - Load and preprocess the image.\n",
        "   - Pass the image through the **DINOv2 model** to obtain detected objects and bounding boxes.\n",
        "\n",
        "4. **Match Detected Objects with Caption Words**:\n",
        "   - Compare detected object names with caption words using **synonym matching (WordNet)**.\n",
        "   - Apply **fuzzy matching (RapidFuzz)** to detect close matches.\n",
        "\n",
        "5. **Draw Bounding Boxes on Matched Objects**:\n",
        "   - If an object from the image matches a user-provided object name, draw a bounding box on the image.\n",
        "   - Save and display the processed image.\n",
        "\n",
        "## Expected Output:\n",
        "- An image with bounding boxes drawn around detected objects that match the user-provided caption.\n",
        "- A printed list of detected objects and matched objects.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import spacy\n",
        "import difflib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from transformers import AutoProcessor, AutoModelForObjectDetection\n",
        "\n",
        "# Load Spacy NLP model for extracting nouns\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load DINO model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "processor = AutoProcessor.from_pretrained(\"facebook/detr-resnet-101\") # use 50 for resent-50\n",
        "model = AutoModelForObjectDetection.from_pretrained(\"facebook/detr-resnet-101\").to(device)\n",
        "\n",
        "def extract_objects_from_caption(caption):\n",
        "    \"\"\"Extract objects (nouns) from user caption.\"\"\"\n",
        "    doc = nlp(caption)\n",
        "    return [token.lemma_ for token in doc if token.pos_ == \"NOUN\"]\n",
        "\n",
        "def get_synonyms(word):\n",
        "    \"\"\"Find synonyms using WordNet.\"\"\"\n",
        "    synonyms = set()\n",
        "    for syn in wn.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name().lower().replace(\"_\", \" \"))\n",
        "    return synonyms\n",
        "\n",
        "def match_objects(detected_objects, caption_objects):\n",
        "    \"\"\"Match detected objects with caption objects using synonyms and fuzzy matching.\"\"\"\n",
        "    matched_objects = set()\n",
        "    object_dict = defaultdict(set)\n",
        "\n",
        "    # Precompute synonyms for detected objects\n",
        "    for obj in detected_objects:\n",
        "        object_dict[obj].update(get_synonyms(obj))\n",
        "\n",
        "    for caption_obj in caption_objects:\n",
        "        caption_synonyms = get_synonyms(caption_obj)\n",
        "\n",
        "        for detected_obj, synonyms in object_dict.items():\n",
        "            if detected_obj in caption_synonyms or caption_obj in synonyms:\n",
        "                matched_objects.add(detected_obj)\n",
        "            else:\n",
        "                # Use fuzzy matching for closely related names\n",
        "                if difflib.get_close_matches(caption_obj, [detected_obj], cutoff=0.7):\n",
        "                    matched_objects.add(detected_obj)\n",
        "\n",
        "    return matched_objects\n",
        "\n",
        "def detect_objects(image_path):\n",
        "    \"\"\"Detect objects in the image using DINO.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Error: Unable to load image at {image_path}. Check if the file exists.\")\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    inputs = processor(images=image_rgb, return_tensors=\"pt\").to(device)\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    scores = outputs.logits.softmax(-1)[0, :, :-1].detach().cpu().numpy()\n",
        "    labels = outputs.logits.argmax(-1)[0].detach().cpu().numpy()\n",
        "    boxes = outputs.pred_boxes[0].detach().cpu().numpy()\n",
        "\n",
        "    detected_objects = []\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    for i in range(len(scores)):\n",
        "        score = scores[i].max()\n",
        "        label = labels[i]\n",
        "        box = boxes[i]\n",
        "\n",
        "        if score > 0.25:\n",
        "            cx, cy, w, h = box  # Corrected to use center x, y\n",
        "            x = int((cx - w / 2) * width)\n",
        "            y = int((cy - h / 2) * height)\n",
        "            w = int(w * width)\n",
        "            h = int(h * height)\n",
        "            object_name = model.config.id2label.get(label, f\"Unknown_{label}\")\n",
        "            detected_objects.append((object_name, (x, y, w, h)))\n",
        "\n",
        "    return detected_objects, image\n",
        "\n",
        "def draw_boxes(image, detected_objects, matched_objects):\n",
        "    \"\"\"Draw bounding boxes around matched objects with thin sharp borders.\"\"\"\n",
        "    for obj, box in detected_objects:\n",
        "        if obj in matched_objects:\n",
        "            x, y, w, h = box\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Thinner border\n",
        "            cv2.putText(image, obj, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "    cv2.imwrite(\"output.jpg\", image)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    image_path = \"/content/20250326_232148.jpg\"\n",
        "    caption = \"person , bottle , cloths , bed , laptop , pages , paper , bag ,chair , box , wires , charger , mat , window  \"\n",
        "\n",
        "    text_objects = extract_objects_from_caption(caption)\n",
        "    detected_objects, image = detect_objects(image_path)\n",
        "    matched_objects = match_objects([obj for obj, _ in detected_objects], text_objects)\n",
        "\n",
        "    print(f\"Detected Objects: {[obj for obj, _ in detected_objects]}\")\n",
        "    print(f\"Matched Objects: {matched_objects}\")\n",
        "\n",
        "    draw_boxes(image, detected_objects, matched_objects)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "YJpdQbaBia4V",
        "outputId": "0c651464-39c0-4aee-b897-c04151e3130c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#smaller resnet\n",
        "\"\"\"\n",
        "# Object Detection & NLP-based Object Matching using DINO (DEtection Transformer) and NLP\n",
        "----------------------------------------------------------------------------------------\n",
        "## Overview:\n",
        "This script performs object detection in images using Meta AI's **DINO (DETR ResNet-101)** model and\n",
        "matches the detected objects with user-specified textual descriptions. It leverages **Natural Language Processing (NLP)**\n",
        "for extracting object names from text and **WordNet** for finding synonyms. Fuzzy string matching is also used to improve matching accuracy.\n",
        "\n",
        "## Key Technologies & Libraries Used:\n",
        "1. **PyTorch & Hugging Face Transformers**:\n",
        "   - Loads and runs the **DINOv2 (DETR ResNet-101)** object detection model.\n",
        "   - Uses `AutoProcessor` for preprocessing images before feeding them into the model.\n",
        "   - Uses `AutoModelForObjectDetection` for detecting objects in the image.\n",
        "\n",
        "2. **OpenCV (cv2)**:\n",
        "   - Reads and processes images.\n",
        "   - Draws bounding boxes and labels on detected objects.\n",
        "\n",
        "3. **spaCy (Natural Language Processing)**:\n",
        "   - Extracts nouns from a user-provided text description of objects to be found in the image.\n",
        "\n",
        "4. **WordNet (NLTK)**:\n",
        "   - Generates synonyms for detected and user-provided object names to improve matching accuracy.\n",
        "\n",
        "5. **RapidFuzz (Fuzzy Matching for Object Names)**:\n",
        "   - Matches detected object names with caption words based on similarity percentage.\n",
        "\n",
        "## Process Flow:\n",
        "1. **Load DINO Object Detection Model**:\n",
        "   - Load the **DINOv2 model (DETR ResNet-101)** for object detection.\n",
        "   - Load the **Hugging Face AutoProcessor** for image preprocessing.\n",
        "\n",
        "2. **Extract Object Names from Text Input (Caption Matching)**:\n",
        "   - Parse the text input using `spaCy` to extract **nouns** (e.g., \"chair\", \"bottle\").\n",
        "   - Retrieve synonyms for each word using `WordNet`.\n",
        "\n",
        "3. **Perform Object Detection on Image**:\n",
        "   - Load and preprocess the image.\n",
        "   - Pass the image through the **DINOv2 model** to obtain detected objects and bounding boxes.\n",
        "\n",
        "4. **Match Detected Objects with Caption Words**:\n",
        "   - Compare detected object names with caption words using **synonym matching (WordNet)**.\n",
        "   - Apply **fuzzy matching (RapidFuzz)** to detect close matches.\n",
        "\n",
        "5. **Draw Bounding Boxes on Matched Objects**:\n",
        "   - If an object from the image matches a user-provided object name, draw a bounding box on the image.\n",
        "   - Save and display the processed image.\n",
        "\n",
        "## Expected Output:\n",
        "- An image with bounding boxes drawn around detected objects that match the user-provided caption.\n",
        "- A printed list of detected objects and matched objects.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import spacy\n",
        "import difflib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from transformers import AutoProcessor, AutoModelForObjectDetection\n",
        "\n",
        "# Load Spacy NLP model for extracting nouns\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load DINO model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "processor = AutoProcessor.from_pretrained(\"facebook/detr-resnet-50\") # use 50 for resent-50\n",
        "model = AutoModelForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\").to(device)\n",
        "\n",
        "def extract_objects_from_caption(caption):\n",
        "    \"\"\"Extract objects (nouns) from user caption.\"\"\"\n",
        "    doc = nlp(caption)\n",
        "    return [token.lemma_ for token in doc if token.pos_ == \"NOUN\"]\n",
        "\n",
        "def get_synonyms(word):\n",
        "    \"\"\"Find synonyms using WordNet.\"\"\"\n",
        "    synonyms = set()\n",
        "    for syn in wn.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name().lower().replace(\"_\", \" \"))\n",
        "    return synonyms\n",
        "\n",
        "def match_objects(detected_objects, caption_objects):\n",
        "    \"\"\"Match detected objects with caption objects using synonyms and fuzzy matching.\"\"\"\n",
        "    matched_objects = set()\n",
        "    object_dict = defaultdict(set)\n",
        "\n",
        "    # Precompute synonyms for detected objects\n",
        "    for obj in detected_objects:\n",
        "        object_dict[obj].update(get_synonyms(obj))\n",
        "\n",
        "    for caption_obj in caption_objects:\n",
        "        caption_synonyms = get_synonyms(caption_obj)\n",
        "\n",
        "        for detected_obj, synonyms in object_dict.items():\n",
        "            if detected_obj in caption_synonyms or caption_obj in synonyms:\n",
        "                matched_objects.add(detected_obj)\n",
        "            else:\n",
        "                # Use fuzzy matching for closely related names\n",
        "                if difflib.get_close_matches(caption_obj, [detected_obj], cutoff=0.7):\n",
        "                    matched_objects.add(detected_obj)\n",
        "\n",
        "    return matched_objects\n",
        "\n",
        "def detect_objects(image_path):\n",
        "    \"\"\"Detect objects in the image using DINO.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Error: Unable to load image at {image_path}. Check if the file exists.\")\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    inputs = processor(images=image_rgb, return_tensors=\"pt\").to(device)\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    scores = outputs.logits.softmax(-1)[0, :, :-1].detach().cpu().numpy()\n",
        "    labels = outputs.logits.argmax(-1)[0].detach().cpu().numpy()\n",
        "    boxes = outputs.pred_boxes[0].detach().cpu().numpy()\n",
        "\n",
        "    detected_objects = []\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    for i in range(len(scores)):\n",
        "        score = scores[i].max()\n",
        "        label = labels[i]\n",
        "        box = boxes[i]\n",
        "\n",
        "        if score > 0.25:\n",
        "            cx, cy, w, h = box  # Corrected to use center x, y\n",
        "            x = int((cx - w / 2) * width)\n",
        "            y = int((cy - h / 2) * height)\n",
        "            w = int(w * width)\n",
        "            h = int(h * height)\n",
        "            object_name = model.config.id2label.get(label, f\"Unknown_{label}\")\n",
        "            detected_objects.append((object_name, (x, y, w, h)))\n",
        "\n",
        "    return detected_objects, image\n",
        "\n",
        "def draw_boxes(image, detected_objects, matched_objects):\n",
        "    \"\"\"Draw bounding boxes around matched objects with thin sharp borders.\"\"\"\n",
        "    for obj, box in detected_objects:\n",
        "        if obj in matched_objects:\n",
        "            x, y, w, h = box\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Thinner border\n",
        "            cv2.putText(image, obj, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "    cv2.imwrite(\"output.jpg\", image)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    image_path = \"/20250326_232148.jpg\"\n",
        "    caption = \"person , bottle , cloths , bed , laptop , pages , paper , bag ,chair , box , wires , charger , mat , window  \"\n",
        "\n",
        "    text_objects = extract_objects_from_caption(caption)\n",
        "    detected_objects, image = detect_objects(image_path)\n",
        "    matched_objects = match_objects([obj for obj, _ in detected_objects], text_objects)\n",
        "\n",
        "    print(f\"Detected Objects: {[obj for obj, _ in detected_objects]}\")\n",
        "    print(f\"Matched Objects: {matched_objects}\")\n",
        "\n",
        "    draw_boxes(image, detected_objects, matched_objects)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "f7QyQpAolIV1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}